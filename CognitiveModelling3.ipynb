{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u5ZxAPgK0jGa",
        "WwFxelkNXDi6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries and important arrays (priors, quadrants and images)**"
      ],
      "metadata": {
        "id": "u5ZxAPgK0jGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oWzDcelFFgOb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "priors = [[ 450, 525, 600, 675, 750],[ 750, 825, 900, 975, 1050], [ 900, 975, 1050, 1125, 1200], [ 450, 525, 600, 675, 750, 825, 900, 975, 1050, 1125, 1200]]\n",
        "quadrants = [\"TL\", \"TR\", \"BL\", \"BR\"]\n"
      ],
      "metadata": {
        "id": "EGOC5hibUMfj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for i in range(400):\n",
        "  images.append(i)"
      ],
      "metadata": {
        "id": "X-ZrRkoVUqNA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Memory Functions**"
      ],
      "metadata": {
        "id": "WwFxelkNXDi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chunk(object):\n",
        "\n",
        "    def __init__(self, name, slots):\n",
        "        self.name = name\n",
        "        self.slots = slots\n",
        "        self.encounters = []\n",
        "        self.fan = 0 # How many other chunks refer to this chunk?\n",
        "\n",
        "\n",
        "    def add_encounter(self, time):\n",
        "        \"\"\"\n",
        "        Add an encounter of this chunk at the specified time.\n",
        "        \"\"\"\n",
        "        if time not in self.encounters:\n",
        "            self.encounters.append(time)\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Chunk \" + str(self.name) + \"\\n\" \\\n",
        "        \"Slots: \" + str(self.slots) + \"\\n\" \\\n",
        "        \"Encounters: \" + str(self.encounters) + \"\\n\" \\\n",
        "        \"Fan: \" + str(self.fan) + \"\\n\""
      ],
      "metadata": {
        "id": "y0rORUZGhDNi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "class Model(object):\n",
        "\n",
        "    # Model parameters\n",
        "\n",
        "    ga = 1.0 # spreading activation from the goal (:ga; default: 1.0)\n",
        "    mas = 2.0 # maxmimum spreading (:mas; default: 2.0)\n",
        "\n",
        "    d = 0.5 # decay (:bll; default: 0.5)\n",
        "    s = 0.2 # scale of activation noise (:ans; default: 0)\n",
        "\n",
        "    lf = 0.1 # latency factor (:lf; default: 0.1)\n",
        "    le = 1.0 # latency exponent (:le; default: 1.0)\n",
        "\n",
        "    rt = -1.0 # retrieval threshold (:rt; default: 0.0)\n",
        "\n",
        "    mp = 3.0 # mismatch penalty (:mp)\n",
        "\n",
        "    def __init__(self):\n",
        "        self.time = 0\n",
        "        self.goal = None\n",
        "        self.dm = []\n",
        "\n",
        "\n",
        "    def get_chunk(self, name):\n",
        "        \"\"\"\n",
        "        Find the Chunk given its name\n",
        "        \"\"\"\n",
        "        chunk_idx = [i for i, j in enumerate(self.dm) if j.name == name]\n",
        "        if len(chunk_idx) == 0:\n",
        "            return None\n",
        "        else:\n",
        "            return self.dm[chunk_idx[0]]\n",
        "\n",
        "\n",
        "    def add_encounter(self, chunk):\n",
        "        \"\"\"\n",
        "        Add an encounter of a specified chunk at the current time.\n",
        "        If the chunk does not exist yet, create it first.\n",
        "        \"\"\"\n",
        "\n",
        "        update_fan = False\n",
        "\n",
        "        # If a chunk by this name does not yet exist, add it to DM\n",
        "        if chunk.name not in [chunk.name for chunk in self.dm]:\n",
        "            self.dm.append(chunk)\n",
        "            update_fan = True\n",
        "\n",
        "        # If a chunk by this name does exist, ensure that it has the same slots and slot values\n",
        "        chunk_idx = [i for i, j in enumerate(self.dm) if j.name == chunk.name][0]\n",
        "        if self.dm[chunk_idx].slots != chunk.slots:\n",
        "            raise ValueError(\"Trying to add an encounter to a chunk with the same name (%s) but different slots and/or slot values\" % chunk.name)\n",
        "\n",
        "        # Add an encounter at the current time\n",
        "        self.dm[chunk_idx].add_encounter(self.time)\n",
        "\n",
        "        slot_vals = chunk.slots.values()\n",
        "\n",
        "        # Add slot values as singleton chunks\n",
        "        for v in slot_vals:\n",
        "            if type(v) == str and v not in [ch.name for ch in self.dm]:  # NT: we want some contraints on the adding of chunks\n",
        "                s = Chunk(name = v, slots = {})\n",
        "                self.add_encounter(s)\n",
        "\n",
        "        # Increment the fan of all chunks that this chunk references in its slots\n",
        "        if update_fan:\n",
        "            refs = [i for i, ref in enumerate(self.dm) if ref.name in slot_vals]\n",
        "            for ref in refs:\n",
        "                self.dm[ref].fan += 1\n",
        "\n",
        "\n",
        "    def get_activation_no_noise(self, chunk):\n",
        "        \"\"\"\n",
        "        Get the activation of the specified chunk at the current time, but without noise\n",
        "        \"\"\"\n",
        "        # The specified chunk should exist in DM\n",
        "        if chunk not in self.dm:\n",
        "            raise ValueError(\"The specified chunk (%s) does not exist in DM\" % str(chunk.name))\n",
        "\n",
        "        # There should be at least one past encounter of the chunk\n",
        "        if self.time <= min(chunk.encounters):\n",
        "            raise ValueError(\"Chunk %s not encountered at or before time %s\" % (str(chunk.name), str(self.time)))\n",
        "\n",
        "        baselevel_activation = math.log(sum([(self.time - encounter) ** -self.d for encounter in chunk.encounters if encounter < self.time]))\n",
        "\n",
        "        spreading_activation = self.get_spreading_activation_from_goal(chunk)\n",
        "\n",
        "        return baselevel_activation + spreading_activation\n",
        "\n",
        "\n",
        "    def get_activation(self, chunk):\n",
        "        \"\"\"\n",
        "        Get the activation of the specified chunk at the current time.\n",
        "        \"\"\"\n",
        "        return self.get_activation_no_noise(chunk) + self.noise(self.s)\n",
        "\n",
        "\n",
        "    def get_latency(self, chunk):\n",
        "        \"\"\"\n",
        "        Get the retrieval latency of the specified chunk at the current time.\n",
        "        \"\"\"\n",
        "        activation = self.get_activation(chunk)\n",
        "        return self.lf * math.exp(-self.le * activation)\n",
        "\n",
        "\n",
        "    def noise(self, s):\n",
        "        \"\"\"\n",
        "        Generate activation noise by drawing a value from a logistic distribution with mean 0 and scale s.\n",
        "        \"\"\"\n",
        "        rand = random.uniform(0.001,0.999)\n",
        "        return s * math.log((1 - rand)/rand)\n",
        "\n",
        "\n",
        "    def get_spreading_activation_from_goal(self, chunk):\n",
        "        \"\"\"\n",
        "        Calculate the amount of spreading activation from the goal buffer to the specified chunk.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.goal is None:\n",
        "            return 0\n",
        "\n",
        "        if type(self.goal) is Chunk:\n",
        "            spreading = 0.0\n",
        "            total_slots = 0\n",
        "            for value in self.goal.slots.values():\n",
        "                total_slots += 1\n",
        "                ch1 = self.get_chunk(value)\n",
        "                if ch1 != None and value in chunk.slots.values() and ch1.fan > 0:\n",
        "                    spreading += max(0, self.mas - math.log(ch1.fan))\n",
        "\n",
        "        if total_slots == 0:\n",
        "            return 0\n",
        "\n",
        "        return spreading * (self.ga / total_slots)\n",
        "\n",
        "\n",
        "    def match(self, chunk1, pattern):\n",
        "        \"\"\"\n",
        "        Does chunk1 match pattern in chunk pattern?\n",
        "        \"\"\"\n",
        "        for slot, value in pattern.slots.items():\n",
        "            if not(slot in chunk1.slots and chunk1.slots[slot] == value):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "\n",
        "    def retrieve(self, chunk):\n",
        "        \"\"\"\n",
        "        Retrieve the chunk with the highest activation that matches the request in chunk\n",
        "        Returns the chunk (or None) and the retrieval latency\n",
        "        \"\"\"\n",
        "        bestMatch = None\n",
        "        bestActivation = self.rt\n",
        "        for ch in self.dm:\n",
        "            act = self.get_activation(ch)\n",
        "            if self.match(ch, chunk) and act > bestActivation:\n",
        "                bestMatch = ch\n",
        "                bestActivation = act\n",
        "        if bestMatch == None:\n",
        "            latency = self.lf * math.exp(-self.le * self.rt)\n",
        "        else:\n",
        "            latency = self.lf * math.exp(-self.le * bestActivation) # calculate it here to avoid a new noise draw\n",
        "        return bestMatch, latency\n",
        "\n",
        "    def mismatch(self, value1, value2):\n",
        "        \"\"\"\n",
        "        Calculate the mismatch between two slot values. If the two values are the same, the mismatch is 0.\n",
        "        Otherwise, use the square root of the distance between the numbers as mismatch value\n",
        "        \"\"\"\n",
        "        if value1 == value2:\n",
        "            return 0.0\n",
        "        if type(value1) == str or type(value2) == str:\n",
        "            return None\n",
        "        return -math.sqrt(abs(float(value1) - float(value2)))/5\n",
        "\n",
        "    def partial_match(self, chunk, pattern):\n",
        "        \"\"\"\n",
        "        Retrieve a chunk using partial matching.\n",
        "        \"\"\"\n",
        "        penalty = 0\n",
        "        for slot, value in pattern.slots.items():\n",
        "            if not(slot in chunk.slots):\n",
        "                return None\n",
        "            similarity = self.mismatch(chunk.slots[slot], value)\n",
        "            if similarity == None:\n",
        "                return None\n",
        "            penalty += similarity * self.mp\n",
        "        return penalty\n",
        "\n",
        "\n",
        "    def retrieve_partial(self, chunk, trace=False):\n",
        "        \"\"\"\n",
        "        Retrieve a chunk using partial matching. This version only partially matches on numbers, and will\n",
        "        use a predefined distance function\n",
        "        \"\"\"\n",
        "        bestMatch = None\n",
        "        bestActivation = self.rt\n",
        "        for ch in self.dm:\n",
        "            act = self.get_activation(ch)\n",
        "            penalty = self.partial_match(ch, chunk)\n",
        "\n",
        "            if penalty != None and act + penalty > bestActivation:\n",
        "                bestMatch = ch\n",
        "                bestActivation = act + penalty\n",
        "            if trace == True and penalty != None:\n",
        "                print(\"Chunk %s has activation %f and penalty %f\" % (ch.name, act, penalty))\n",
        "        if bestMatch == None:\n",
        "            latency = self.lf * math.exp(-self.le * self.rt)\n",
        "        else:\n",
        "            latency = self.lf * math.exp(-self.le * bestActivation) # calculate it here to avoid a new noise draw\n",
        "        return bestMatch, latency\n",
        "\n",
        "\n",
        "    def get_retrieval_probability(self, chunk, pattern):\n",
        "        \"\"\"\n",
        "        Returns the probability of retrieving a specific chunk that matches the specified pattern,\n",
        "        given its activation and the activation of the other matching chunks\n",
        "        \"\"\"\n",
        "        activations = dict([(ch, self.get_activation_no_noise(ch))for ch in self.dm if self.match(ch, pattern)])\n",
        "        return math.exp(activations[chunk] / self.s)  / sum([math.exp(a / self.s) for a in activations.values()])\n",
        "\n",
        "\n",
        "    def retrieve_blended_trace(self, pattern, slot):\n",
        "        \"\"\"\n",
        "        Returns a blend of the requested slot value from all chunks in DM that match the specified pattern, weighted by their activation\n",
        "        \"\"\"\n",
        "\n",
        "        latency = self.lf * math.exp(-self.le * self.rt) # Latency is determined by the retrieval threshold\n",
        "\n",
        "        eligible_chunks = [ch for ch in self.dm if self.match(ch, pattern) and slot in ch.slots and ch.slots[slot]]\n",
        "\n",
        "        if not eligible_chunks:\n",
        "            return None, latency\n",
        "\n",
        "        chunk_probs = dict([(ch, math.exp(self.get_activation_no_noise(ch) / self.s)) for ch in eligible_chunks])\n",
        "        blended_value = sum([ch.slots[slot] * prob / sum(chunk_probs.values()) for ch, prob in chunk_probs.items()])\n",
        "\n",
        "        return blended_value, latency\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"\\n=== Model ===\\n\" \\\n",
        "        \"Time: \" + str(self.time) + \" s \\n\" \\\n",
        "        \"Goal:\" + str(self.goal) + \"\\n\" \\\n",
        "        \"DM:\" + \"\\n\".join([str(c) for c in self.dm]) + \"\\n\""
      ],
      "metadata": {
        "id": "BOuuZEEJXKnQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "LHfIDj6qXH-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion to pulses/time functions"
      ],
      "metadata": {
        "id": "cyjBkbfe0upG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(s):\n",
        "  rand = random.uniform(0.001,0.999)\n",
        "  return s * math.log((1 - rand)/rand)\n",
        "\n",
        "def pulses_to_time(pulses, t_0 = 0.011, a = 1.2, b = 0.01, add_noise =True):\n",
        "  time = 0\n",
        "  pulse_duration = t_0\n",
        "  while pulses > 0:\n",
        "    time = time + pulse_duration\n",
        "    pulses = pulses - 1\n",
        "    pulse_duration = a * pulse_duration + add_noise * noise(b * a *  pulse_duration)\n",
        "  return time\n",
        "\n",
        "def time_to_pulses(time, t_0 = 0.011, a = 1.2, b = 0.01, add_noise =True):\n",
        "  pulses = 0\n",
        "  pulse_duration = t_0\n",
        "  while time >= pulse_duration:\n",
        "    time = time - pulse_duration\n",
        "    pulses = pulses + 1\n",
        "    pulse_duration = a * pulse_duration + add_noise * noise(b * a *pulse_duration)\n",
        "  return pulses"
      ],
      "metadata": {
        "id": "gIdbsWcOWI36"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to randomize the quadrants that correspond to each prior"
      ],
      "metadata": {
        "id": "eZb34O9V00kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_assign():\n",
        "  quad = []\n",
        "  quad = quadrants.copy()\n",
        "  prior_quadrants = []\n",
        "  for i in range(len(quad)):\n",
        "    random_quadrant = random.choice(quad)\n",
        "    prior_quadrants.append([random_quadrant, priors[i], \"p\"+str(i+1)])\n",
        "    quad.remove(random_quadrant)\n",
        "  return prior_quadrants\n",
        "\n"
      ],
      "metadata": {
        "id": "U4b6PMVaXi8Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Model"
      ],
      "metadata": {
        "id": "Ncl-VfXy1Dex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def model():\n",
        "\n",
        "  final_dataset = []\n",
        "\n",
        "  # Number of participants\n",
        "  n = 35\n",
        "\n",
        "  # Iterate over each participant\n",
        "  for j in range(n):\n",
        "\n",
        "    # Initialize the model\n",
        "    m = Model()\n",
        "\n",
        "    #Assign different quadrants to prior for each participant\n",
        "    quadrants_priors = random_assign()\n",
        "\n",
        "    # Create the list that is going to contain the reproduction errors of the participants\n",
        "    error_list = []\n",
        "\n",
        "    # Iterate over the blocks (1 practice, 12 analysis)\n",
        "    for k in range(13):\n",
        "\n",
        "      # By default, all of blocks will not be practice\n",
        "      practice = \"no\"\n",
        "\n",
        "      # For odd numbered analysis blocks, the stimuli are random images from the image list.\n",
        "      # The estimated time will be NA as there is no previous block with the same images.\n",
        "      if (k) % 2 != 0 or k == 0:\n",
        "        stimuli = random.sample(range(1, 401), 48)\n",
        "        estimated_time = [\"NA\"]*48\n",
        "\n",
        "      # For even numbered blocks, the same stimuli are shown but in a randomizes order.\n",
        "      # The priors of the respective images from previous block are recorded and appended to the estimated_time list.\n",
        "      else:\n",
        "        previous_stimuli = stimuli\n",
        "        estimated_time = []\n",
        "        random.shuffle(stimuli)\n",
        "        for element in range(len(previous_stimuli)):\n",
        "          for item in range(len(stimuli)):\n",
        "            if previous_stimuli[element] == stimuli[item]:\n",
        "              estimated_time.append(shuffled_quadrants[item][0])\n",
        "\n",
        "      # The list of quadrants and priors that are going to be shown to each participant in each block is created in advanced.\n",
        "      # The array shuffled_quadrants, contains 48 randomly chosen quadrants, the respective prior intervals and the prior block name.\n",
        "      shuffled_quadrants = []\n",
        "      shuffled_quadrants.append(quadrants_priors * 12)\n",
        "      (random.shuffle(shuffled_quadrants[0]))\n",
        "      shuffled_quadrants = shuffled_quadrants[0]\n",
        "\n",
        "      quadrants_array = []\n",
        "      priors_array = []\n",
        "      block_array = []\n",
        "\n",
        "      # Separate the quadrants, prior list and prior block names.\n",
        "      for p in range(48):\n",
        "\n",
        "        quadrants_array.append(shuffled_quadrants[p][0])\n",
        "        priors_array.append(random.choice(shuffled_quadrants[p][1]) / 1000)\n",
        "        block_array.append(shuffled_quadrants[p][2])\n",
        "\n",
        "      # Iterate over every trial\n",
        "      for i in range(48):\n",
        "\n",
        "        # Model time is advanced 300ms until the thicker frame and white background appears in one of the quadrants.\n",
        "        m.time += 0.3\n",
        "\n",
        "        # The model is advanced 375ms until an image appears in the selected quadrant\n",
        "        m.time += 0.375\n",
        "\n",
        "        # The image appears and lasts the corresponding sample interval of time\n",
        "        random_quadrant = quadrants_array[i]\n",
        "\n",
        "        random_prior = priors_array[i]\n",
        "\n",
        "\n",
        "        # If the block is a practice check, the image is a circle (0)\n",
        "        if k == 0 and i <= 15:\n",
        "          stimulus = 0\n",
        "\n",
        "        # Else, the image is chosen from the randomly pickes images\n",
        "        stimulus = stimuli[i]\n",
        "\n",
        "        prior_block = block_array[i]\n",
        "\n",
        "        # The model advances the sample interval time and converts it to pulses. An encounter is added to memory\n",
        "        prior_pulses = time_to_pulses(random_prior)\n",
        "        m.time += random_prior\n",
        "        c2 = Chunk(name = \"set \" + (random_quadrant) + str(prior_pulses) + str(stimulus), slots = {\"type\": \"pulses_set\", \"pulse\": prior_pulses})\n",
        "        m.add_encounter(c2)\n",
        "\n",
        "        # The model time is advanced 5ms to avoid infinite activation\n",
        "        m.time += 0.05\n",
        "\n",
        "        # The model performs a blended retrieval of the sample interval and converts it to time\n",
        "        blend_pattern = Chunk(name = \"blended-test\", slots = {\"type\": \"pulses_set\"})\n",
        "        retrieved_interval = pulses_to_time(m.retrieve_blended_trace(blend_pattern, \"pulse\")[0])\n",
        "\n",
        "        # The model is then advanced the reproduced interval as well as the time of recall (latency)\n",
        "        m.time += (retrieved_interval)\n",
        "        m.time += m.retrieve_blended_trace(blend_pattern, \"pulse\")[1]\n",
        "\n",
        "        # The retrieved pulse interval is also added to memory\n",
        "        c3 = Chunk(name = \"set_ret \" + (random_quadrant) + str(prior_pulses) + str(stimulus) + str(retrieved_interval), slots = {\"type\": \"pulses_ret\", \"pulse\": time_to_pulses(retrieved_interval)})\n",
        "        m.add_encounter(c3)\n",
        "\n",
        "        # The model is advanced 250ms until the cycle begins again.\n",
        "        m.time += 0.25\n",
        "\n",
        "        # The following list of ifs statements check whether previous intervals exist in order to record them, up to 7 intervals away.\n",
        "        # If they don't, then a NA will be recorded instead\n",
        "        if i > 0:\n",
        "          ts1 = priors_array[i-1]\n",
        "        else:\n",
        "          ts1 = \"NA\"\n",
        "        if i > 1:\n",
        "          ts2 = priors_array[i-2]\n",
        "        else:\n",
        "          ts2 = \"NA\"\n",
        "        if i > 2:\n",
        "          ts3 = priors_array[i-3]\n",
        "        else:\n",
        "          ts3 = \"NA\"\n",
        "        if i > 3:\n",
        "          ts4 = priors_array[i-4]\n",
        "        else:\n",
        "          ts4 = \"NA\"\n",
        "        if i > 4:\n",
        "          ts5 = priors_array[i-5]\n",
        "        else:\n",
        "          ts5 = \"NA\"\n",
        "        if i > 5:\n",
        "          ts6 = priors_array[i-6]\n",
        "        else:\n",
        "          ts6 = \"NA\"\n",
        "        if i > 6:\n",
        "          ts7 = priors_array[i-7]\n",
        "        else:\n",
        "          ts7 = \"NA\"\n",
        "\n",
        "        # The previous quadrant is checked to see whether it is the same or differetn\n",
        "        if (quadrants_array[i] == quadrants_array[i-1]) and i > 0:\n",
        "          rep = \"rep\"\n",
        "        else:\n",
        "          rep = \"swi\"\n",
        "\n",
        "        # The calcluation of outliers is done at this step. The reproduction errors of a participant are recorded.\n",
        "        # Using the fomula for the z-score, the current reproduction error is either deemed an outlier or not.\n",
        "        median = np.median(error_list)\n",
        "        mad = np.median(np.absolute(error_list - median))\n",
        "        outlier = ((round(round(retrieved_interval,2) - random_prior,2)) - median) / mad\n",
        "        if outlier > 2.5 or outlier < -2.5:\n",
        "          is_outlier = \"TRUE\"\n",
        "        else:\n",
        "          is_outlier = \"FALSE\"\n",
        "\n",
        "        # If the block number is 0 and the trial is under 16, the block is set to be practice block\n",
        "        if k == 0 and i <= 16:\n",
        "          practice = \"yes\"\n",
        "\n",
        "        # The current reproduction error is appended to the list, for future calculation of outliers.\n",
        "        error_list.append(round(round(retrieved_interval,2) - random_prior,2))\n",
        "\n",
        "        # Finally, all the data is collected and appended to an array, which will be what the model function returns.\n",
        "        final_dataset.append([len(final_dataset)+1,\"S00\"+str(j), k, practice, random_quadrant, str(stimulus), prior_block, random_prior, round(retrieved_interval,2) - random_prior, j, (j+1)*(k+1)*(i+1), round(retrieved_interval,2), is_outlier,ts1,ts2,ts3,ts4,ts5,ts6,ts7,rep,estimated_time[i]])\n",
        "\n",
        "        # If the practice block finishes, the corresponding block loop is over, so the analysis trials can start\n",
        "\n",
        "        if i == 47:\n",
        "          m.time += random.randint(5, 300)\n",
        "\n",
        "        if k == 0 and i == 15:\n",
        "          break\n",
        "\n",
        "\n",
        "  return final_dataset"
      ],
      "metadata": {
        "id": "QWauOk-QlnR2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = model()"
      ],
      "metadata": {
        "id": "LWqWq0DrXxTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05e29bd-3b84-403b-8271-8951181981c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "<ipython-input-17-d1c0b9f32cf8>:150: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  outlier = ((round(round(retrieved_interval,2) - random_prior,2)) - median) / mad\n",
            "<ipython-input-17-d1c0b9f32cf8>:150: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  outlier = ((round(round(retrieved_interval,2) - random_prior,2)) - median) / mad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert and download the CSV file"
      ],
      "metadata": {
        "id": "VYqY3FRxALnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(final_model)\n",
        "headerList = [\"\",\"student_nr\",\"Block_nr\",\"practice\",\"quadrant\",\"stimulus\",\"prior\",\"ts\",\"repr_error\",\"sub_id\",\"trial_index\",\"tr\",\"outlier\",\"ts_1\",\"ts_2\",\"ts_3\",\"ts_4\",\"ts_5\",\"ts_6\",\"ts_7\",\"qrep\",\"ts_stim\"]\n",
        "df.to_csv(\"final_model.csv\", header=headerList, index=False)\n",
        "\n",
        "dat = pd.read_csv(\"final_model.csv\")"
      ],
      "metadata": {
        "id": "eKQJDSPN5PL5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"final_model.csv\")"
      ],
      "metadata": {
        "id": "Hoi5w9I6526a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}